//program to implement feed forward neural network with three hidden layers for classification on CIFAR-10 dataset

import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import matplotlib.pyplot as plt

# Load and preprocess data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
y_train_cat = to_categorical(y_train, num_classes=10)
y_test_cat = to_categorical(y_test, num_classes=10)

# Hyperparameter search space
hidden_units_options = [32, 64, 128]
activations = ['relu', 'tanh', 'sigmoid']

# Training loop initialization
result_set = []

# Loop over hyperparameters
for hidden_units in hidden_units_options:
    for activation in activations:

        # Define model
        model = Sequential([
            Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D((2, 2)),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(hidden_units, activation=activation),
            Dense(10, activation='softmax')
        ])

        # Compile model
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

        # Train model (using a simple, quick fit for the example)
        # Note: In a real-world hyperparameter search, you'd use callbacks and proper epochs.
        history = model.fit(x_train, y_train_cat, epochs=1, batch_size=32,
                            validation_data=(x_test, y_test_cat), verbose=0)

        # Get test accuracy
        loss, test_accuracy = model.evaluate(x_test, y_test_cat, verbose=0)

        # Store results
        model_info = {
            'Hidden_units': hidden_units,
            'Activation': activation,
            'Accuracy': round(test_accuracy * 100, 4)
        }
        result_set.append(model_info)

# Find the best model
best_result = max(result_set, key=lambda x: x['Accuracy'])

# Print best result
print("Best Model:")
print(f"Accuracy: {best_result['Accuracy']}% achieved with {best_result['Hidden_units']} hidden units and '{best_result['Activation']}' activation.")

# Class names for CIFAR-10
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

# Testing the best model (retrain for best model or load weights if available)
# Assuming the model from the last loop iteration or a re-trained one is used here.
# For simplicity, we'll re-use the structure of the best model and assume it's the one trained last.

# Select random images from the test set
num_samples = 5
random_indices = np.random.choice(len(x_test), num_samples, replace=False)
sample_images = x_test[random_indices]
sample_labels = y_test[random_indices]

# Predict
predictions = model.predict(sample_images)

# Visualize predictions
plt.figure(figsize=(10, 5))
for i in range(num_samples):
    predicted_label = class_names[np.argmax(predictions[i])]
    true_label = class_names[sample_labels[i][0]] # y_test is not one-hot encoded here
    
    plt.subplot(1, num_samples, i + 1)
    plt.imshow(sample_images[i])
    plt.title(f"True: {true_label}\nPredicted: {predicted_label}")
    plt.axis('off')

plt.tight_layout()
plt.show()

# Print sample predictions to console (optional, based on image 2)
# for i in range(num_samples):
#     predicted_label = class_names[np.argmax(predictions[i])]
#     true_label = class_names[sample_labels[i][0]]
#     print(f"Image {i+1}: True Label: {true_label}, Predicted Label: {predicted_label}")
